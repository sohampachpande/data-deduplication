{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JupHAmJWmtXw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dedup_lib.datasets import dedupDataset\n",
    "from dedup_lib.models import NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pi9jMMQUrUn4",
    "outputId": "4e4825a9-33f9-4886-da4c-2bf74753f8df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util Function\n",
    "\n",
    "def binary_acc(y_pred, y_ground):\n",
    "\n",
    "    # print(y_pred, y_ground)  \n",
    "    y_pred_tag = torch.round(y_pred)\n",
    "    # print(y_pred_tag, y_ground)  \n",
    "\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_ground).sum().float()\n",
    "    # print(correct_results_sum)\n",
    "    acc = correct_results_sum/y_ground.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEq0I_WtwVYq"
   },
   "source": [
    "## Data Preparation\n",
    "### Remove all data with entries which do not have embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Glove Embedding Model\n",
    "\n",
    "The glove model weights have to be downloaded from https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "\n",
    "Update the path in GLOVE_DIR accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR=\"../pre-trained-models/glove.6B/\"\n",
    "dimension=100\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bZLwOZCKyxwS"
   },
   "outputs": [],
   "source": [
    "data_path = \"../data-extraction/1AllDuplicates_5NoDuplicates.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path, usecols=['w1', 'w2', 'isDuplicate']).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df['w1'] = df['w1'].astype(str)\n",
    "df['w2'] = df['w2'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove words without embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MCxHsRfxwH8X"
   },
   "outputs": [],
   "source": [
    "def hasEmbedding(w):\n",
    "    if w.lower().strip() in embeddings_index:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "df['w1_has_embedding']=df['w1'].apply(lambda x:hasEmbedding(x))\n",
    "df['w2_has_embedding']=df['w2'].apply(lambda x:hasEmbedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tRxGRnXLwZ-d"
   },
   "outputs": [],
   "source": [
    "df = df[df['w1_has_embedding']==True]\n",
    "df = df[df['w2_has_embedding']==True]\n",
    "\n",
    "df = df.drop(['w1_has_embedding', 'w2_has_embedding'], axis=1)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DBaNshAtwJk0"
   },
   "outputs": [],
   "source": [
    "df_train = df[:int(0.7*len(df))].reset_index(drop=True)\n",
    "df_test = df[int(0.7*len(df)):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EV431VJvzwll"
   },
   "source": [
    "# Train pytorch NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ViXtxAfO1ruy"
   },
   "outputs": [],
   "source": [
    "train_set, test_set = dedupDataset(df_train, embeddings_index), dedupDataset(df_test, embeddings_index)\n",
    "train_loader = DataLoader(train_set, batch_size=100)\n",
    "test_loader = DataLoader(test_set, batch_size=len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(d=dimension).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sAkUA8nEz2Z7"
   },
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOZuCrV81U6i",
    "outputId": "44a2afda-50e1-4219-f87b-026912802875"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sohampachpande/miniconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\tloss : 0.6001343727111816\t accuracy : 86.0\n",
      "epoch 5\tloss : 0.3651868999004364\t accuracy : 86.0\n",
      "epoch 10\tloss : 0.29831990599632263\t accuracy : 86.0\n",
      "epoch 15\tloss : 0.23527204990386963\t accuracy : 86.0\n",
      "epoch 20\tloss : 0.16881319880485535\t accuracy : 98.0\n",
      "epoch 25\tloss : 0.11710987240076065\t accuracy : 99.0\n",
      "epoch 30\tloss : 0.08522161841392517\t accuracy : 99.0\n",
      "epoch 35\tloss : 0.06379342824220657\t accuracy : 99.0\n",
      "epoch 40\tloss : 0.04789978265762329\t accuracy : 99.0\n",
      "epoch 45\tloss : 0.03635437786579132\t accuracy : 99.0\n",
      "epoch 50\tloss : 0.02817995660007\t accuracy : 100.0\n",
      "epoch 55\tloss : 0.02230760268867016\t accuracy : 100.0\n",
      "epoch 60\tloss : 0.01765982061624527\t accuracy : 100.0\n",
      "epoch 65\tloss : 0.014102832414209843\t accuracy : 100.0\n",
      "epoch 70\tloss : 0.011316223070025444\t accuracy : 100.0\n"
     ]
    }
   ],
   "source": [
    "epochs=75\n",
    "#forward loop\n",
    "losses = []\n",
    "accur = []\n",
    "for i in range(epochs):\n",
    "    for j,(x_train,y_train) in enumerate(train_loader):\n",
    "        x_train,y_train = x_train.to(device), y_train.to(device)\n",
    "        #calculate output\n",
    "        output = model(x_train)\n",
    "\n",
    "        #calculate loss\n",
    "        loss = loss_fn(output,y_train.reshape(-1,1))\n",
    "\n",
    "        acc = binary_acc(output, y_train.reshape(-1,1))\n",
    "        #backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%5 == 0:\n",
    "        losses.append(loss)\n",
    "        accur.append(acc)\n",
    "        print(\"epoch {}\\tloss : {}\\t accuracy : {}\".format(i,loss,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yt9yafQb24e5",
    "outputId": "d20c412b-a821-469d-b7d1-7c674d7cad0d"
   },
   "outputs": [],
   "source": [
    "y_truth_list = []\n",
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for j,(x_test,y_test) in enumerate(test_loader):\n",
    "        x_test,y_test = x_test.to(device), y_test.to(device)\n",
    "        #calculate output\n",
    "        output = model(x_test)\n",
    "\n",
    "        acc = binary_acc(output, y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHBSUEQr7Tmg",
    "outputId": "1e107b44-6da9-4c7b-a44e-cfe64437bf2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(97., device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RedxBQCu84c-"
   },
   "outputs": [],
   "source": [
    "y_pred = torch.round(output.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9KTaCkcx_Z9d"
   },
   "outputs": [],
   "source": [
    "y_pred_arr = np.asarray(y_pred.cpu())\n",
    "y_test_arr = np.asarray(y_test.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats about results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gwW7CFzf_qDg"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9712/2896759666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmakeCFwithStats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, classification_report\n",
    "from utils import makeCFwithStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdSd3bwi_80e",
    "outputId": "3daeb592-f0aa-4ebe-f620-2959c805b972"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_arr, y_pred_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "MlJ0NZv8ACaL",
    "outputId": "2cb320b8-5db5-45a8-ae85-293fd72194b0"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_arr, y_pred_arr)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeCFwithStats(y_test_arr, y_pred_arr)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "category-dedup-glove.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "e2db466ff52d66022f9f91c796fc91b92f6c42d56a30aade30d4e70cac3fc604"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
